# Paraphrasing
Paraphrasing using LSTM Autoencoders

# Dataset Used:
- Unlabeled paws dataset from: https://github.com/google-research-datasets/paws
- Link to download: https://storage.googleapis.com/paws/english/paws_wiki_unlabeled_final.tar.gz

# Pretrained Word Embeddings Used:

- GloVe from GitHub: https://github.com/stanfordnlp/GloVe

	For this project is used `Wikipedia 2014 + Gigaword 5 (6B tokens, 400K vocab, uncased, 300d vectors, 822 MB download)`

- Direct link to download: http://nlp.stanford.edu/data/wordvecs/glove.6B.zip

  
